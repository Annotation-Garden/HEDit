# LLM Configuration
LLM_BASE_URL=http://localhost:11435
LLM_MODEL=gpt-oss:20b
LLM_TEMPERATURE=0.1  # Low temperature (0.0-1.0) for consistent, less creative responses

# HED Schema Configuration (JSON format)
# NOTE: Paths are auto-detected!
# - In Docker: Uses /app/hed-schemas/schemas_latest_json
# - Locally: Uses ~/git/hed-schemas/schemas_latest_json
# - Override with environment variable if needed
HED_SCHEMA_DIR=  # Leave empty for auto-detection
HED_SCHEMA_VERSION=8.4.0

# HED Validator Configuration
# NOTE: Paths are auto-detected!
# - In Docker: Uses /app/hed-javascript
# - Locally: Uses ~/git/hed-javascript
# - Override with environment variable if needed
HED_VALIDATOR_PATH=  # Leave empty for auto-detection
USE_JS_VALIDATOR=true

# API Configuration
API_HOST=0.0.0.0
API_PORT=38427
API_WORKERS=4

# Workflow Configuration
MAX_VALIDATION_ATTEMPTS=5
MAX_TOTAL_ITERATIONS=10

# Logging
LOG_LEVEL=INFO
